---
tags:
  - TODO
aliases: 
data: "`2025-03-13 17:18`"
---
- # Memory manager:
	-  gestisce la memoria principale, assegna e de-alloca la memoria ai processi.
	- Tiene traccia della memoria libera e occupata
	- è un componente software a differenza dell’MMU.
- # Binding:
	- Lo fa il compilatore ed è l’associazione degli indirizzi logici con quelli fisici.
	- Può avvenire durante:
		- ## Compilazione :
			- Indirizzi calcolati al momento della compilazione e saranno gli stessi durante tutto il programma 
			- Codice generato detto _assoluto_
				- Un esempio può essere il _kernel_
			- ![[Pasted image 20250313172457.png]]
			- Non richiede hardware speciale, veloce e semplice ma non funziona con la _multiprogrammazione_ perché 2 processi che eseguono lo stesso programma necessiterebbero di allocare la stessa cella di memoria.
		- ## caricamento :
			- Il codice generato dal compilatore non ha indirizzi assoluti ma relativi.
			- Codice detto _rilocabile_:
			- Il loader si occupa dei riferimenti ad indirizzi di memoria coerentemente al punto iniziale di caricamento
			- ![[Pasted image 20250313172935.png]]
			- Permette la multiprogrammazione non richiede hardware speciale, però gli serve una traduzione degli indirizzi da parte del loader e quindi di particolari file eseguibili
			- 
		- ## esecuzione .
			- Individuazione degli indirizzi effettuata durante l’esecuzione dalla _MMU_ che trasforma gli indirizzi logici in quelli fisici.
			- ![[Pasted image 20250320151314.png]]
			- Il problema è che la MMU è un componente complesso.
			- Questo binding permette il multitasking,
	- ## Indirizzi logici:
		- Ogni processo è associato ad uno spazio di indirizzamento logico.
		- Gli indirizzi usati in un processo sono Indirizzi logici, ovvero riferimenti a Questo spazio di indirizzamento
	- ## Fisici :
		- Sono gli indirizzi reali della memoria principale che sono associati agli indirizzi logici.
		- L’MMU traduce da indirizzi logici a fisici
- # MMU:
	- ## ES:
		- ![[Pasted image 20250320152956.png]]
		- Si prende un registro di rilocazione $R$ che permette alla MMU di trasformare gli indirizzi logici $[0,MAX]$ in indirizzi fisici $[R,R+MAX]$. 
	- L’MMU può fare anche attività di controllo:
		- Il registro limite viene usato per proteggere la memoria.
		- ![[Pasted image 20250320153710.png]]
		- Se un processo tenta di accedere ad un indirizzo fuori dal suo spazio di indirizzamento logico, la MMU lo rileva e genera una [[Trap e interrupt#^ca5cf6|Trap]].
- # Loading dinamico:
	- Consente di caricare certi moduli di libreria solo quando vengono richiamati.
	- Implementato avendo le routine su un disco che vengono caricate quando servono senza caricare tutte quelle che non servono.
	- Però sta al programmatore conoscere e utilizzare queste cose, il [[Sistema operativo]] fornisce solo la possibilità.
- # Linking dinamico:
	- Unisce il codice scritto con le librerie usate generando l’eseguibile.
	- Posticipa il linking alle librerie al momento del primo riferimento durante l’esecuzione.
	- Ciò permette di avere eseguibili più compatti, risparmiare di conseguenza la memoria e aggiornare automaticamente delle versioni delle librerie che verranno caricate all’attivazione successiva dei programmi 
	- `Dlopen` consente di caricare librerie dinamiche a runtime.
		- Ed è il metodo con cui vengono caricati i _plug-In_
- 
- # Paginazione:
	- _Riduce il fenomeno di frammentazione interna e elimina la frammentazione esterna._
	- _Lo spazio di indirizzi logici_ viene diviso in _pagine_ di dimensione fissa.
	- _La memoria fisica_ viene divisa in _frame_ di dimensione uguale a quella delle pagine.
	- Quando si allocano dei processi si cerca ovunque in memoria dei frame sufficienti per contenere le pagine del processo.
	- ## ES:
		- ![[Pasted image 20250320165231.png]]
		- ![[Pasted image 20250320165551.png]]
	- ## Scegliere dimensione delle pagine:
		- Deve essere una potenza di 2 per facilitare la traduzione degli indirizzi.
		- Questa scelta deriva da un trade-off:
			- Se le pagine sono piccole la tabella delle pagine cresce di dimensione.
			- Se le pagine sono grandi si ha frammentazione interna che farà perdere grandi quantità di memoria.
		- _E si suppone che i frame della pagina inizino da un indirizzo multiplo di 4096_.
	- ## Implementazione della tabella delle pagine:
		- Si potrebbe inserire in un insieme di registri ad alta velocità per facilitarne l’accesso, però sarebbe troppo costoso.
- # Translation lookaside buffer (TLB):
	- Insieme di registri associativi ad alta velocità $O(1)$ 
	- Ogni registro ha 2 parti:
		- _Chiave_: che di solito è il numero di pagina
		- _Dato_  
	- Esistono tante coppie fatte in questo modo e quando viene fatta la richiesta di un dato con una chiave viene confrontata con tutte le chiavi presenti contemporaneamente e se c’è una corrispondenza si restituisce il dato(TLB hit), altrimenti (TLB miss) si usa la tabella in memoria, quest’ultima azione è una trap e viene gestita dal [[Sistema operativo]]. 
	- ![[Pasted image 20250320171358.png]]
	- Agisce come memoria cache per le tabelle delle pagine
	- L’hardware per implementarla è costoso, con dimensioni dell’ordine di $8 -2048$ registri
- # Segmentazione:
	- Concetto di organizzazione della memoria.
	- Si basa sul fatto che un processo ha bisogno della memoria per vari motivi:
		- Codice
		- Dati
		- Stack
		- Magari anche aree di memoria condivise con altri processi.
	- Quindi separa le aree di memoria in base ai loro scopi.
		- Codice per esempio sarebbe meglio fosse un area di memoria di sola lettura, chiamata _area text_
		- Le aree _dati_ possono essere condivise.
		- L’area _stack_ non deve essere condivisa tra processi e deve essere read/write
	- Lo spazio di indirizzamento logico deve essere diviso in segmenti contigui di dimensione variabile, ogni segmento ha _nome_ e _lunghezza_ definiti.
	- Ogni riferimento di memoria è una coppia `<nome, offset>`
	- Questa suddivisione spetta al _compilatore_ o al _programmatore_
	- ![[Pasted image 20250321094522.png]]
	- ## Problemi:
		- Usare la paginazione da sola porta a problemi che si avevano con l’allocazione contigua.
	- ## Collaborazione:
		- Si potrebbe usare la segmentazione e la paginazione insieme combinando i metodi di entrambi.
		- Indirizzo diviso in :
			- Gli ultimi 12 bit sono l’_offset_ 
			- I primi 4 bit sono il _numero del segmento_
		- Bisogna inoltre che la MMU abbia il supporto per entrambe le tecniche.
		- Quindi risultiamo avere entrambi i benefici di entrambi:
			- _Condivisione e protezione_ della segmentazione
			- _Riduzione della frammentazione_ della paginazione
- # Memoria virtuale:
	- Permette di eseguire dei processi che non sono completamente caricati in memoria
	- Permette quindi a dei programmi [[Concorrenza||concorrenti]], che hanno necessità di una quantità di memoria maggiore di quella disponibile, di eseguirsi.
	- Limita le prestazioni del sistema, ma permette di avere un sistema più flessibile.
		- Load:
		- Store: dato l’indirizzo di un dato ricorda il dato all’indirizzo specificato.
	- ## ES:
		- L’area dedicata alla gestione degli errori (si spera) viene usata poche volte.
		- Strutture dati con una dimensione fissata dall’inizio che però raramente utilizzano tutta
	- ## Implementazione:
		- Ogni [[Concorrenza#^68dcd8|processo]] ha accesso ad uno _spazio di indirizzamento virtuale_ 
		- Gli indirizzi virtuali logici possono essere mappati su indirizzi fisici della memoria principale oppure su una memoria secondaria.
			- Se si accede alla memoria secondaria, i dati sono trasferiti nella memoria centrale e se quella memoria è piena dei dati vengono trasferiti in una memoria secondaria e completare il trasferimento.
	- ## Paginazione a richiesta:
		- Usiamo la paginazione, solo che nella tabella delle pagine viene aggiunto un campo che indica l’indirizzo nella memoria secondaria e un bit che indica se la pagina è disponibile nella memoria centrale.
		- Se si tenta di accedere ad una pagina che manca nella memoria centrale, il processore genera una [[Trap e interrupt#^ca5cf6|trap]] (_page fault_) e il sistema operativo con il _pager_ si occupa di trasferire la pagina in memoria centrale.
	- ![[Pasted image 20250321102727.png]]
	- ## Pager/swapper:
		- ### Swap:
			- Prendere l’intera memoria del processo sospenderlo e poi mettere la memoria del processo in quella secondaria e riattivare poi il processo.
			- _swap-in_: quando si porta la memoria secondaria in quella principale.
			- _swap-out_: quando si porta la memoria principale in quella secondaria.
		- Nella paginazione su richiesta si fa swap solo delle pagine che servono.
	- ## Gestione page fault:
		- Quando non ci sono frame liberi serve liberarne uno e si sceglie di eliminare la pagina _meno utile_ usando un algoritmo di rimpiazzamento:
		- ### Stringa di riferimenti:
			- Una sequenza di riferimenti in memoria che poi sono i tutti i numeri di pagina.
		- ### Anomalia di Belady:
			- Non è detto che aumentando il numero di frame allora diminuisca il numero di page fault.
		- ### Algoritmi di sostituzione/rimpiazzamento:
			- Si invalida la pagina da togliere facendo in modo che non venga più considerata in memoria e se un processo tenta di accedervi è come se non la vedesse.
			- Poi si aggiorna la frame table con il frame libero.
			- L’algoritmo minimizza il numero di _page fault_ trovando quindi la pagina meno utile in questo momento.
			- #### Valutazione:
				- Gli algoritmi vengono valutati esaminando come si comportano quando applicati ad una _stringa di riferimenti_ in memoria.
			- #### algoritmi a Stack:
				- Data la stringa di riferimenti $s$ 
				- Indico con $S_{t}(s,A,m)$ l’insieme delle pagine nella memoria centrale al tempo $t$ dell’algoritmo $A$ data una memoria di  $m$ frame
				- Quindi un algoritmo è detto _a stack_ se per ogni stringa $s$ e tempo $t$ si ha che:
					- $$S_{t}(s,A,m)\subseteq S_{t}(s,A,m+1)$$
				- ##### Teorema:
					- Si si ha un algoritmo a stack non possono esserci casi della _anomalia di Belady_
				- ##### Dim:
					- Si prende un $S_{t}(s,A,m)$ e $S_{t}(s,A,m+1)$ se caricassi un altra pagina $p$ ci sarebbe page fault?
						- Se  $p$ appartiene al primo allora anche al secondo quindi non c’è page fault in entrambi.
						- Se $p$ appartiene al secondo e non al primo allora c’è page fault in entrambi.
						- Se $p$ non appartiene a nessuno dei due allora non c’è page fault in entrambi.
							- Quindi aumentando il numero di frame non si ha un aumento di _page fault_.
			- #### FIFO:
				- Butta via la pagina che è stata caricata per prima in memoria.
				- Però il fatto che una pagina sia stata caricata per prima non significa che non sarà più usata.
				- ![[Pasted image 20250321111403.png|700]]
			- #### MIN:
				- Si sceglie la pagina che verrà acceduta nel futuro più lontano.
				- Questo algoritmo garantisce il minimo numero di page fault.
				- ![[Pasted image 20250321111935.png|650]]
			- #### LRU (least recently used):
				- Si sceglie la pagina che è stata acceduta meno recentemente.
				- è basato sul presupposto che la distanza tra due riferimenti successivi alla stessa pagina non vari eccessivamente.
				- ![[Pasted image 20250321112249.png|650]]
				- Per fare si che funzioni l’MMU dovrebbe tenere traccia di tutti i riferimenti fatti ad ogni pagina usando un contatore che viene incrementato ad ogni accesso in memoria. 
				- Questo però è molto costoso perché si necessiterebbe di controllare l’overflow del contatore o averne uno molto alto. 
				- ##### Approssimare l’algoritmo
					- ###### Additional-Reference-Bit-Algorithm
						- Per approssimare questo algoritmo si tiene conto se una pagina è stata acceduta impostandone i reference bit a 1 e poi periodicamente si controlla quali siano state accedute e si resetta il bit.
						- ![[Pasted image 20250405183343.png|650]]
					- ###### Second chance algorithm:
						- Corrisponde ad un caso particolare dell’algoritmo precedente dove la dimensione della “storia” è 1
						- Le pagine in memoria vengono gestite come una lista circolare,
						- Partendo dalla posizione successiva all’ultima pagina caricata, la lista viene scandita secondo la seguente regola:
							- Se la pagina _è stata acceduta_ il reference bit viene messo a 0  
							- Altrimenti la pagina selezionata diventa la “vittima”.
						- ![[Pasted image 20250405184019.png|700]]
				- ##### Teorema: 
					- L’algoritmo _LRU_ è a stack.
				- ##### Dim:
					- Ogni riferimento alla stringa dei riferimenti sposta la pagina in cima allo stack, facendo scorrere le successive
						- ![[Pasted image 20250405182355.png|300]]
					- Poi l’algoritmo tiene in memoria le prime $m$ pagine dello stack
					- Quindi l’algoritmo _è a stack_ siccome l’insieme delle $m$ pagine in cima è un sottoinsieme delle $m+1$ pagine in cima allo stack.
			- #### LFU (least frequently used):
				- Mantengo un contatore del numero di accessi ad una pagina 
				- La frequenza è il valore del contatore diviso il tempo di permanenza in memoria
				- La pagina con valore minore viene eliminata.
	- ## Allocazione:
		- Un algoritmo di allocazione sceglie quanti frame assegnare ad ogni singolo [[Concorrenza#^68dcd8|processo]]
		- _locale_: ogni processo ha un insieme proprio di frame è ciò è poco flessibile.
		- _globale_: tutti i processi possono allocare tutti i frame presenti nel sistema, può portare a _trashing_.
- # Trashing:
	- Un processo o un sistema si dice che è in _trashing_ quando spende più tempo per la paginazione che per l’esecuzione.
	- ## Cause:
		- In un sistema con allocazione globale, avviene perché i processi provano continuamente a rubarsi i frame a vicenda.
			- Ovvero non riescono a tenersi in memoria i frame utili a breve termine e quindi generano dei _page fault_ frequentemente.
	- ## ES:
		- 
- # Link Utili:
	- 